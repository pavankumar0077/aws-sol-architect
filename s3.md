S3
--
Amazon S3 Use cases
--
- Backup and storage
- Disaster Recovery
- Archive
- Hybrid Cloud storage
- Application hosting
- Media hosting
- Data lakes & big data analy
- Software delivery
- Static website

Amazon S3 - Buckets
--
- Amazon $3 allows people to store objects (files) in "buckets" (directories)
- Buckets must have a globally unique name (across all regions all accounts)
- Buckets are defined at the region level
- 53 looks like a global service but buckets are created in a region
- Naming convention
- No uppercase, No underscore
- 3-63 characters long
- Not an IP/
- Must start with lowercase letter or number
- Must NOT start with the prefix xn-
- Must NOT end with the suffix -salias

Amazon S3 - Objects
--
- Objects (files) have a Key
- The key is the FULL path:
- s3://my-bucket/my_file.txt
- 53://my-bucket/my_folder|/another_folder/my_file.txt
- The key is composed of prefix + object name
- s3://my-bucket/my_folder|/another_folder/my_file.txt
- There's no concept of "directories" within buckets
(although the Ul will trick you to think otherwise)
- Just keys with very long names that contain slashes ("'")
-  Object values are the content of the body:
- Max. Object Size is 5TB (5000GB)
- If uploading more than 5GB, must use "multi-part upload"
- Metadata (list of text key / value pairs - system or user metadata)
- Tags (Unicode key / value pair - up to 10) - useful for security / lifecycle
- Version ID (if versioning is enabled)

Access the bucket objects
--
- We can access the bucket object directly by clicking on OPEN
![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/28405d10-3cce-445e-8da0-09852698d124)

- It opens a very long URL -- WHICH IS CALLED AS S3 PRE-SIGNED URL which is very very long url (It contains the signature that i am verify user)
- If we use OBJECT ULR -- WE WILL GET THE ACCESS DEINED ERROR BY DEFAULT.

S3 Security
--
### User-Based
- IAM Policies - which API calls should be allowed for a specific user from AM
### Resource-Based
- Bucket Policies - bucket wide rules from the S3 console - allows cross account
- Object Access Control List (ACL) - finer grain (can be disabled)
- Bucket Access Control List (ACL) - less common (can be disabled)
### Note: an IAM principal can access an 53 object if
- The user IAM permissions ALLOW it OR the resource policy ALLOWS it
- AND there's no explicit DENY

### Encryption: encrypt objects in Amazon S3 using encryption keys

S3 Bucket Policies
--
![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/8be4caa4-ef12-4c1b-b89a-1a39946b3174)

- JSON based policies
- Rescues bets and objects
- Priate Aunt Ar user to apply the
policy to

- Use S3 bucket for policy to:
- Grant public access to the bucket
- Force objects to be encrypted at upload
- Grant access to another account (Cross
Account)

![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/dcd000c5-551b-48ff-beca-cdbb9bc6672d)

![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/11c14cdd-f62e-4d62-a734-1fd16bc94502)

![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/68516dbf-e4bb-469b-b51e-331368547a48)

![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/15cfa1df-d6b6-4b6c-9ae7-816db355f933)

![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/aa6ea6dd-78ed-4faf-a6de-d03389bc80e7)

### Policy generator

![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/5c6caad4-621c-4794-999e-18ccbef6c9a5)

- Here we have options to GET THE EXAMPLES AND POLICY GENERATOR.
![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/677c96df-abeb-4b6f-a9dd-fb9e717a7bbe)
- Here in ARN we need to add **"/*"**


S3 - Static Website Hosting
--
![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/45d25ef0-9501-41ec-98b7-25f3eabb4c93)

S3 - Versioning
--
- You can version your files in Amazon S3
- It is enabled at the bucket level
- Same key overwrite will change the "version": 1, 2, 3.....
- It is best practice to version your buckets
- Protect against unintended deletes (ability to restore a version)
- Easy roll back to previous version
### Notes:
- Any file that is not versioned prior to enabling versioning will
have version "null"
- Suspending versioning does not delete the previous versions

- Different visions will be added
- Delete -- USES DELETE MARKER, WILL NOT DELETE THE ACTUAL OBJECT.
- We can restore it.

S3 - Replication (CRR - Crosss Region replication & SRR - Same Region Replication)
--
![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/1b2fa3ed-c048-48c4-9520-6cb99c2b1c90)
- Must enable Versioning in source and destination buckets
- Cross-Region Replication (CRR)
- Same-Region Replication (SRR)
- Buckets can be in different AWS accounts
- Copying is asynchronous
- Must give proper IAM permissions to 53
### Use cases:
- CRR - compliance, lower latency access, replication across accounts
- SRR - log aggregation, live replication between production and test
accounts

- After you enable Replication, only new objects are replicated
- Optionally, you can replicate existing objects using 53 Batch Replication
- Replicates existing objects and objects that failed replication
- For DELETE operations
- Can replicate delete markers from source to target (optional setting)
- Deletions with a version ID are not replicated (to avoid malicious deletes)
- There is no "chaining" of replication
- If bucket I has replication into bucket 2, which has replication into bucket 3
- Then objects created in bucket I are not replicated to bucket 3

Hands on
--
Step 1: Create 2 buckets with versioning enable for SRR, So bucket 1 will be in one region and 2 will be in another region.
Step 2 : Go to bucket which you want to replicate to another bucket in another region
-- Open bucket -- Management Replications -- Add rule -- Apply for all objects
![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/842c6617-ef57-4c5f-a6ac-02d77aaf4699)
-- Enter the destination bucket name and it will find the region automatically.
-- Create new IAM Role 
![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/39838429-bfff-4685-a2c0-cc6e5ec473fe)
-- If you want to replicate exisitng objects in the bucket you have to use ONE TIME BATCH PROCESSING.
![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/0ea0c140-eeee-406f-8090-75d757b09353)

- Here testpavanbucketexample1 -- is the source bucket -- as i have uploaded a file in the source bucket it is replicated to destignation bucket testpavanbucketecampl2 bukect.
![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/0c013364-9b72-4136-9e8b-71dbdc8a3d6d)

- ![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/11bc0aa3-434f-49a8-8b01-3377cd037b83)
- Version ID is same for both objects.
- We fine delete marker replication option as well
- ![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/ba3ec7c4-6927-4a06-ac1b-3632ea30f967)

S3 - Storage Classes
--
### Amazon S3 Standard - General Purpose
- 99.99% Availability
- Used for frequently accessed data
- Low latency and high throughput
- Sustain 2 concurrent facility failures
- Use Cases: Big Data analytics, mobile & gaming applications, content distribution...
  
### Amazon S3 Standard-Infrequent Access (IA)
- For data that is less frequently accessed, but requires rapid access when needed
- Lower cost than S3 Standard
- 99.9% Availability
- Use cases: Disaster Recovery, backups

### Amazon S3 One Zone-Infrequent Access
- High durability (99.999999999%) in a single AZ; data lost when AZ is destroyed
- 99.5% Availability
- Use Cases: Storing secondary backup copies of on-premise data, or data you can recreate

### Amazon 53 Glacier Instant Retrieval
- Low-cost object storage meant for archiving / backup
- Pricing: price for storage + object retrieval cost
- Millisecond retrieval, great for data accessed once a quarter
- Minimum storage duration of 90 days

### Amazon S3 Glacier Flexible Retrieval
- Expedited (I to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) - free
- Minimum storage duration of 90 days

### Amazon S3 Glacier Deep Archive
- Standard (12 hours), Bulk (48 hours)
- Minimum storage duration of 180 days

### Amazon S3 Intelligent Tiering
- Small monthly monitoring and auto-tiering fee
- Moves objects automatically between Access Tiers based on usage
- There are no retrieval charges in S3 Intelligent-Tiering
- Frequent Access tier (automatic): default tier
- Infrequent Access tier (automatic): objects not accessed for 30 days
- Archive Instant Access tier (automatic): objects not accessed for 90 days
- Archive Access tier (optional): configurable from 90 days to 700+ days
- Deep Archive Access tier (optional): config. from 180 days to 700+ days

- Can move between classes manually or using 53 Lifecycle configurations

![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/21b3bff3-9ff2-4107-bfd8-e591a786dbdf)

![image](https://github.com/pavankumar0077/aws-sol-architect/assets/40380941/aa9d3dd7-fb5e-4c5d-989d-c26d6bb6c7f2)

53 Durability and Availability
--
### Durability:
- High durability (99.999999999%, 1 | 9'5) of objects across multiple AZ
- If you store 10,000,000 objects with Amazon S3, you can on average expect to
incur a loss of a single object once every 10,000 years
- Same for all storage classes
### Availability:
- Measures how readily available a service is
- Varies depending on storage class
- Example: 53 standard has 99.99% availability = not available 53 minutes a year


